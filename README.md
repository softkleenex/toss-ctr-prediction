# Toss NEXT ML Challenge - CTR Prediction

í† ìŠ¤ ê´‘ê³  í´ë¦­ë¥  ì˜ˆì¸¡ AI ê²½ì§„ëŒ€íšŒ ì°¸ê°€ í”„ë¡œì íŠ¸

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

- **ëŒ€íšŒ**: Toss NEXT 2025 ML Challenge - ê´‘ê³  í´ë¦­ë¥ (CTR) ì˜ˆì¸¡
- **ì£¼ìµœ**: Dacon x í† ìŠ¤
- **ê¸°ê°„**: 2025.09 ~ 2025.10
- **ëª©í‘œ**: í† ìŠ¤ ì•± ë‚´ ê´‘ê³  í´ë¦­ í™•ë¥  ì˜ˆì¸¡ (Binary Classification)

## ğŸ¯ ìµœì¢… ì„±ì 

| ì œì¶œ | ìŠ¤ì½”ì–´ | ìˆœìœ„ | ì„¤ëª… |
|------|--------|------|------|
| **Supreme Evolved Refined** | **0.3434805649** | ìƒìœ„ê¶Œ | ìµœê³  ì„±ì  |
| Final Push v1 | 0.3434775373 | - | 2ìœ„ ìŠ¤ì½”ì–´ |
| Enhanced V2 | 0.3425593061 | - | ê°œì„ ëœ ì „ì²˜ë¦¬ ë²„ì „ |

**í‰ê°€ ì§€í‘œ**: AUC (Area Under the Curve)

## ğŸ›  ê¸°ìˆ  ìŠ¤íƒ

### í•µì‹¬ ê¸°ìˆ 
- **ì–¸ì–´**: Python 3.12
- **ML í”„ë ˆì„ì›Œí¬**: LightGBM, XGBoost
- **ë°ì´í„° ì²˜ë¦¬**: Pandas, NumPy
- **íŠ¹ì§• ì¶”ì¶œ**: Scipy, Scikit-learn

### ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬
```python
lightgbm==4.x      # GPU ê°€ì† Gradient Boosting
xgboost==2.x       # ì•™ìƒë¸” ë‹¤ì–‘ì„±
pandas==2.x        # ë°ì´í„° ì²˜ë¦¬
numpy==1.x         # ìˆ˜ì¹˜ ì—°ì‚°
scipy==1.x         # í†µê³„ ë° ë³€í™˜
```

## ğŸ“Š ë°ì´í„°ì…‹

- **Train**: 10.7M rows, ~8.8GB (Parquet)
- **Test**: 1.5M rows, ~1.3GB (Parquet)
- **Features**: ìµëª…í™”ëœ ì‚¬ìš©ì/ê´‘ê³ /ì»¨í…ìŠ¤íŠ¸ í”¼ì²˜
- **Target**: clicked (0 or 1)
- **íŠ¹ì§•**:
  - ì‹¤ì œ í† ìŠ¤ ì•± ê´‘ê³  ë…¸ì¶œ/í´ë¦­ ë¡œê·¸
  - ë³´ì•ˆìƒ í”¼ì²˜ëª… ìµëª…í™”
  - ë†’ì€ í´ë˜ìŠ¤ ë¶ˆê· í˜• (Click rate: 1.91%)

## ğŸ— ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1. ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
```
Raw Data â†’ Missing Value Handling â†’ Feature Engineering â†’ Sampling â†’ Model Training
```

### 2. ëª¨ë¸ ì•™ìƒë¸” êµ¬ì¡°
```
â”œâ”€â”€ LightGBM (Primary)
â”‚   â”œâ”€â”€ 5-Fold Cross Validation
â”‚   â”œâ”€â”€ 5 Different Seeds
â”‚   â””â”€â”€ GPU Acceleration
â”œâ”€â”€ XGBoost (Diversity)
â”‚   â””â”€â”€ CUDA Support
â””â”€â”€ Weighted Ensemble
```

## ğŸš€ í•µì‹¬ ì „ëµ

### 1. Advanced Preprocessing
```python
# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
- ì¹´í…Œê³ ë¦¬í˜•: -999 (íŠ¹ë³„ê°’)
- ì—°ì†í˜•: Median Imputation

# ë°ì´í„° ìƒ˜í”Œë§
- Balanced Sampling (1:1)
- Imbalanced Sampling (1:1.5)
- Large Sample (3.5M)
```

### 2. Feature Engineering (42+ Features)

#### ìƒí˜¸ì‘ìš© í”¼ì²˜
- ê³±ì…ˆ, ë‚˜ëˆ—ì…ˆ, ì¡°í™”í‰ê· , ê¸°í•˜í‰ê· 
- ì˜ˆ: `history_a_1 Ã— history_b_21`

#### í†µê³„ í”¼ì²˜
- Mean, Std, Skewness, Kurtosis
- Quantiles (Q25, Q75, IQR)
- CV (Coefficient of Variation)
- MAD (Median Absolute Deviation)

#### ì‹œê°„ ì¸ì½”ë”©
```python
# ë‹¤ì¤‘ ì£¼ê¸° sin/cos ë³€í™˜
for period in [24, 12, 8, 6]:
    hour_sin = sin(2Ï€ Ã— hour / period)
    hour_cos = cos(2Ï€ Ã— hour / period)

# í”¼í¬ íƒ€ì„ indicator
- is_morning_rush (7-9ì‹œ)
- is_lunch (11-13ì‹œ)
- is_prime_time (19-22ì‹œ)
```

#### ë‹¤í•­ì‹ í”¼ì²˜
- ì œê³±, ì„¸ì œê³±, ì œê³±ê·¼
- log1p, exp ë³€í™˜

### 3. Model Training

**LightGBM ìµœì  íŒŒë¼ë¯¸í„°**
```python
{
    'objective': 'binary',
    'metric': 'auc',
    'num_leaves': 200,
    'learning_rate': 0.012,
    'feature_fraction': 0.65,
    'bagging_fraction': 0.75,
    'lambda_l1': 0.05,
    'lambda_l2': 0.05,
    'device': 'gpu',
    'num_boost_round': 2500
}
```

**ì•™ìƒë¸” ì „ëµ**
- 5-Fold Ã— 5 Seeds = 25ê°œ LightGBM ëª¨ë¸
- XGBoost ì¶”ê°€ (ë‹¤ì–‘ì„± í™•ë³´)
- ê°€ì¤‘ í‰ê·  (Balanced sample ê°€ì¤‘ì¹˜ ë†’ì„)

### 4. Calibration Strategy

6ê°€ì§€ Calibration ë°©ë²• ì ìš©:

1. **Supreme Optimal**: `0.248 + 0.504 Ã— rank`
2. **Refined**: `0.2478 + 0.5042 Ã— rank`
3. **Aggressive**: `0.252 + 0.496 Ã— rank`
4. **Quantile Transform**: Uniform distribution
5. **Power Law**: `rank^0.95`
6. **Sigmoid Stretch**: `sigmoid(8 Ã— (rank - 0.5))`

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
toss-ctr-prediction/
â”œâ”€â”€ README.md                    # í”„ë¡œì íŠ¸ ê°œìš” ë° ì‚¬ìš©ë²•
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ CONTRIBUTING.md              # ê¸°ì—¬ ê°€ì´ë“œë¼ì¸
â”œâ”€â”€ requirements.txt             # Python íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â”œâ”€â”€ SUBMISSION_RECORD.md         # ì œì¶œ ê¸°ë¡ ë° ì ìˆ˜
â”œâ”€â”€ HOW_TO_GITHUB.md            # GitHub ì—…ë¡œë“œ ê°€ì´ë“œ
â”œâ”€â”€ GITHUB_UPLOAD_GUIDE.md      # ìƒì„¸ ì—…ë¡œë“œ ê°€ì´ë“œ
â”œâ”€â”€ PORTFOLIO_STATUS.md         # í¬íŠ¸í´ë¦¬ì˜¤ ì™„ì„± ìƒíƒœ
â”‚
â”œâ”€â”€ src/                        # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ supreme_evolved_training.py  # ìµœê³  ì„±ì  ëª¨ë¸ (0.3434)
â”‚   â””â”€â”€ enhanced_v2_training.py      # ê°œì„ ëœ ì „ì²˜ë¦¬ ëª¨ë¸
â”‚
â”œâ”€â”€ docs/                       # ìƒì„¸ ë¬¸ì„œ
â”‚   â”œâ”€â”€ APPROACH.md             # ì „ëµ ë° ë°©ë²•ë¡  (10,000+ words)
â”‚   â”œâ”€â”€ FEATURES.md             # Feature Engineering ìƒì„¸ ê°€ì´ë“œ
â”‚   â””â”€â”€ RESULTS.md              # ì‹¤í—˜ ê²°ê³¼ ë° ì„±ëŠ¥ ë¶„ì„
â”‚
â”œâ”€â”€ data/                       # ë°ì´í„° í´ë” (.gitignore)
â”‚   â”œâ”€â”€ train.parquet           # í•™ìŠµ ë°ì´í„° (10.7M rows)
â”‚   â””â”€â”€ test.parquet            # í…ŒìŠ¤íŠ¸ ë°ì´í„° (1.5M rows)
â”‚
â””â”€â”€ submissions/                # ì œì¶œ íŒŒì¼ (.gitignore)
    â”œâ”€â”€ supreme_evolved_refined_*.csv   # #1: 0.3434805649
    â”œâ”€â”€ final_push_v1_*.csv             # #2: 0.3434775373
    â””â”€â”€ enhanced_v2_*.csv               # #3: 0.3425593061
```

### ğŸ“„ ì£¼ìš” íŒŒì¼ ì„¤ëª…

| íŒŒì¼ | ì„¤ëª… | ë¼ì¸ ìˆ˜ |
|------|------|---------|
| **README.md** | í”„ë¡œì íŠ¸ ì „ì²´ ê°œìš” ë° Quick Start | 279 |
| **src/supreme_evolved_training.py** | ìµœê³  ì„±ì  ë‹¬ì„± ëª¨ë¸ ì½”ë“œ (AUC: 0.3434) | 650+ |
| **src/enhanced_v2_training.py** | ê°œì„ ëœ ì „ì²˜ë¦¬ ë° ê¸°ë³¸ FE ëª¨ë¸ | 219 |
| **docs/APPROACH.md** | ì „ëµ, ë°©ë²•ë¡ , íŒŒì´í”„ë¼ì¸ ìƒì„¸ ì„¤ëª… | 370 |
| **docs/FEATURES.md** | 42+ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìƒì„¸ ê°€ì´ë“œ | 500+ |
| **docs/RESULTS.md** | ì‹¤í—˜ ê²°ê³¼, ì„±ëŠ¥ ë¶„ì„, ì‹¤íŒ¨ ì‚¬ë¡€ | 600+ |
| **SUBMISSION_RECORD.md** | ì „ì²´ ì œì¶œ ê¸°ë¡ ë° ìµœì  ì„¤ì • | 78 |
| **CONTRIBUTING.md** | ì½”ë“œ ê¸°ì—¬ ê°€ì´ë“œë¼ì¸ | 150+ |

## ğŸ”¬ ì‹¤í—˜ ë° ê²°ê³¼

### ì£¼ìš” ì‹¤í—˜

| ì‹¤í—˜ | AUC Score | ê°œì„ ì  | ë¹„ê³  |
|------|-----------|--------|------|
| Baseline (22 features) | 0.3409 | - | ê¸°ë³¸ ëª¨ë¸ |
| + Feature Engineering | 0.3425 | +0.0016 | 28ê°œ í”¼ì²˜ |
| + Advanced FE (42+) | **0.3434** | **+0.0025** | **ìµœì¢… ë² ìŠ¤íŠ¸** |
| + Ensemble (25 models) | 0.3434 | +0.0000 | ì•ˆì •ì„± í–¥ìƒ |

### Feature Importance (Top 10)

```
1. history_b_21      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 12.3%
2. history_a_1       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  11.8%
3. feat_b_3          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   10.2%
4. feat_c_8          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     8.7%
5. history_b_30      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      7.5%
6. inventory_id      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       6.8%
7. feat_a_1          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        5.9%
8. age_group         â–ˆâ–ˆâ–ˆâ–ˆ         4.6%
9. hour              â–ˆâ–ˆâ–ˆâ–ˆ         4.3%
10. feat_b_1         â–ˆâ–ˆâ–ˆ          3.8%
```

## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

### ì„±ê³µ ìš”ì¸
1. **ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§**: ë‹¨ìˆœ í”¼ì²˜ë³´ë‹¤ ìƒí˜¸ì‘ìš©/í†µê³„ í”¼ì²˜ê°€ íš¨ê³¼ì 
2. **ë‹¤ì–‘í•œ ìƒ˜í”Œë§ ì „ëµ**: Balanced, Imbalanced, Large ì¡°í•©
3. **ì•™ìƒë¸”ì˜ í˜**: ë‹¨ì¼ ëª¨ë¸ ëŒ€ë¹„ ì•ˆì •ì„± í¬ê²Œ í–¥ìƒ
4. **Calibration ìµœì í™”**: Rank-based calibrationì´ ê°€ì¥ íš¨ê³¼ì 

### ì‹¤íŒ¨ ë° êµí›ˆ
1. **ê³¼ë„í•œ í”¼ì²˜ ì¶”ê°€**: 93ê°œ í”¼ì²˜ ì‹œ ì˜¤íˆë ¤ ì„±ëŠ¥ í•˜ë½ (-0.11)
2. **ë‹¨ìˆœ ì•™ìƒë¸”ì˜ í•œê³„**: ë‹¨ìˆœ í‰ê· ë³´ë‹¤ ê°€ì¤‘ í‰ê· ì´ íš¨ê³¼ì 
3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì²­í‚¹ ë° GC í•„ìˆ˜

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### í™˜ê²½ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### í•™ìŠµ ì‹¤í–‰
```bash
# ê¸°ë³¸ í•™ìŠµ
python src/main_training_pipeline.py

# GPU ê°€ì† (CUDA í•„ìš”)
python src/main_training_pipeline.py --device gpu

# ì•™ìƒë¸” í•™ìŠµ
python src/models/ensemble.py --n_models 25
```

### ì˜ˆì¸¡ ìƒì„±
```bash
python src/predict.py --model_path models/best_model.pkl
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### GPU í™œìš©
- LightGBM GPU ëª¨ë“œ: í•™ìŠµ ì†ë„ 5-10ë°° í–¥ìƒ
- XGBoost CUDA: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ íš¨ìœ¨í™”

### ë©”ëª¨ë¦¬ ìµœì í™”
```python
# Float32 ì‚¬ìš©
X = X.astype(np.float32)

# ì²­í‚¹ ì²˜ë¦¬
for chunk in pd.read_parquet('train.parquet', chunksize=100000):
    process_chunk(chunk)

# Garbage Collection
del train_df
gc.collect()
```

## ğŸ“– ìƒì„¸ ë¬¸ì„œ

### 1. [APPROACH.md](docs/APPROACH.md)
ì „ì²´ ì ‘ê·¼ ë°©ë²• ë° ì „ëµì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.
- ë¬¸ì œ ë¶„ì„ ë° ë°ì´í„° íŠ¹ì„±
- ì „ì²˜ë¦¬ ì „ëµ (ê²°ì¸¡ì¹˜, ìƒ˜í”Œë§)
- Feature Engineering (42+ í”¼ì²˜)
- ëª¨ë¸ë§ ë° ì•™ìƒë¸” ì „ëµ
- Calibration ìµœì í™”
- ì‹¤íŒ¨ ì‚¬ë¡€ ë° êµí›ˆ

### 2. [FEATURES.md](docs/FEATURES.md)
Feature Engineering ìƒì„¸ ê°€ì´ë“œ
- ê¸°ë³¸ í”¼ì²˜ 22ê°œ ì„¤ëª…
- ì—”ì§€ë‹ˆì–´ë§ í”¼ì²˜ 20ê°œ ì„¤ëª…
- í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
- í”¼ì²˜ ìƒì„± íŒŒì´í”„ë¼ì¸ ì½”ë“œ

### 3. [RESULTS.md](docs/RESULTS.md)
ì‹¤í—˜ ê²°ê³¼ ë° ì„±ëŠ¥ ë¶„ì„
- ìµœì¢… ì„±ì  ìš”ì•½
- ì‹¤í—˜ íˆìŠ¤í† ë¦¬ (Phase 1~5)
- ì„±ëŠ¥ ê°œì„  ê³¼ì • ê·¸ë˜í”„
- ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê³¼ì •
- ì•™ìƒë¸” ì „ëµ ë¹„êµ
- Calibration ì‹¤í—˜ ê²°ê³¼

### 4. [SUBMISSION_RECORD.md](SUBMISSION_RECORD.md)
ì œì¶œ ê¸°ë¡ ë° ì ìˆ˜
- Top 3 ì œì¶œ ìƒì„¸
- ì „ì²´ ì œì¶œ íˆìŠ¤í† ë¦¬
- ì‹¤íŒ¨ ì‚¬ë¡€
- ìµœì  ì„¤ì •

## ğŸ“š ì°¸ê³  ìë£Œ

- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Dacon Competition](https://dacon.io/competitions/official/236575/overview/description)

## ğŸ¤ ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ëŠ” Dacon x í† ìŠ¤ CTR ì˜ˆì¸¡ ëŒ€íšŒ ì°¸ê°€ì‘ì…ë‹ˆë‹¤.

ê¸°ì—¬ë¥¼ ì›í•˜ì‹œë©´ [CONTRIBUTING.md](CONTRIBUTING.md)ë¥¼ ì°¸ì¡°í•´ì£¼ì„¸ìš”.

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

MIT License

---

**ê°œë°œ ê¸°ê°„**: 2025.09 ~ 2025.10
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025.10.13
